\section{Abstract}

\section{Introduction}

Conversational chatbots have been a subject of interest for many years. While
it is not difficult to create a chatbot that is capable of generating phrasing
and sentences. It is much harder to have the program initiate human-like
conversation as well as provide accurate answers to questions. In order for the
conversation to sound natural to a human communicating with the chatbot, it must
be able to utilize a dialogue model trained on a large enough sample of human
conversation so that it can extrapolate data when none is available. Meanwhile,
for responses to be accurate, the chatbot would have to lookup questions and
responses within some form of data store, which would provide accurate but
generic-sounding answers for anything within, while also having difficulty in
answering questions not included within the database. The effectiveness of these
two different types of chatbots are on two ends of the same spectrum, as one
prioritizes conversation realism at the cost of information accuracy, while the
other guarantees accuracy at the cost of conversation uniqueness. For our
CSC200/200H chatbot assignment, we've decided to implement a Computer Science
advising chatbot using both methods, where one uses a Question and Answer model
with database query and the other uses a fine-tuned Conversation model, both
provided by the ``rust-bert'' crate in Rust
(\verb|https://github.com/guillaume-be/rust-bert|). We compare the
implementation difficulty as well as maintenance difficulty between the two
different chatbots to see what makes each approach stand-out.

\section{Contributions}

This chatbot project is implemented by the following team members, listed in
alphabetical order, with specific details on contributions as follows:

\begin{itemize}
\item \textbf{Adian Goldfarb (agoldfa7):} % TODO List contributions here
\item \textbf{Paul Ouellette (pouellet):} % TODO List contributions here
\item \textbf{Rafaello Sanna (rsanna):} % TODO List contributions here
\item \textbf{Yiyao Yu (yyu57):} Performed initial CDCS database parsing and
manual data filtering, implemented main chatbot framework and Q\&A chatbot
database load/store and lookup
\end{itemize}

\section{Project Specifications and Assumptions}

The overarching idea behind the assignment is very open-ended. The only thing
that is required is to implement a chatbot that is capable of fulfilling the
role of advising students in the Computer Science department through a cli
interface. Because of this, we identified two problems that we would like to
analyze and attempt to solve for this assignment:

\begin{enumerate}
\item to what extent could the chatbot recognize and respond to natural
language input?
\item how factual are the statements outputted by the chatbot?
\end{enumerate}

Problem (1) is a reasonable question to ask: since what we are implementing is a
chatbot, there should be some amount of focus on the ``chat'' aspect of the bot.
It needs to be able to receive and respond to the user's questions as in a
natural language such as English. Having the user converse with the bot using a
limited set of grammatical constructs or a ``fill in the blanks'' input is too
limiting for conversation. At minimum, the chatbot needs to be able to identify
natural language queries and respond accordingly, regardless of whether the
response is mechanical or not.

For (2), the response of the chatbot needs to be as factual as possible. Since
this is an advising chatbot, it needs to provide information that is accurate
enough for the user to act upon. We recognize that this is difficult for an
actual human advisor to achieve, as even we may make mistakes in conveying
information, therefore, we are only requiring that the chatbot provides
information at roughly the same accuracy as a new human advisor who is advising
his first student. This means that the chatbot may provide information that is
incorrect, but for the majority of the time the general frame of the response
should be accurate. Note that this does not deal with unrelated responses to
conversation, issues stemming from the chatbot not being able to recognize the
user's intent should fall under problem (1) as it is a problem of language
processing.

However, even with a focus on two specific problems for this assignment, the
overall scope of this project is still too large. Designing realistic chatbots
that are capable of providing accurate information part of ongoing research at
large corporations such as Apple or Microsoft. We are unable to satisfy all
types of conversation within our timeline of one week of design and analysis.
Therefore, the following assumptions have been made in order to limit the scope
of the chatbot project:

\begin{enumerate}
\item The user is rational and always provides input relating to advising
\item All courses mentioned should be in the format CSCXXX, with no spaces
between the number and the department, and the department is stylized as
capitalized letters.
\item There is a maximum of one course information mentioned per user input
All courses mentioned are in the Computer Science department.
\item (For Q\&A model only) All user inputs are questions. And these questions
should not result in a boolean (yes or no) answer
\end{enumerate}

Assumption (1) is made out of rationality. In an actual serious setting, a user
would probably not ask a advising chatbot about its favorite color just like how
a student wouldn't ask a professor his or her favorite ramen flavor during an
advising session. Asking such questions would throw-off most humans, which are
already better at handling random questions than a bot. Measuring correctness
of response from random input giberish is meaningless when we already know that
the chatbot does not have a correct answer. While it may be possible to filter
out such user input in some way that preserves ``naturalness'' of the
conversation. Our group decided to focus on the two problems that are listed
above.

Assumption (2) is made out of convenience. We already know that how information
is presented to a transformer-based model may affect whether it recognizes
specific tokens or not. And since we provided all the data in the form described
above, this assumption allows us to not have to do repeated work for training
models or providing contexts for ``CSC171'', ``csc171'', ``CSC 171'', or even
``cSc 171'', since semantics of the course number is the only thing that matters
here. If user representation really matters, this assumption can be safely
removed by performing an extra search and replace on the user input string,
which should allow the correct tokens to be passed to the chatbot model.

Assumption (3) is made due to our resource constraints. While we could
theoretically train/fine-tune a model to recognize relations between two
different courses, our group does not have the resources or time to train such a
model within the given one-week time frame (for $n$ courses, there would be
$O(n^2)$ amount of work instead of $O(n)$). Meanwhile, using only training data
from one course at a time allows us to better fine-tune our models, making the
output results more accurate.

Assumption (4) is made out of necessity, as the Q\&A model that we used only
supports answering questions based on a given context. While we could have merged
the Q\&A model with another model to provide responses regardless of whether the
input was an open-ended question, such an approach sacrifices the accuracy of
answers provided by the Q\&A model.

\section{Implementation Details}

Based on the problems that we've identified and would like to solve as well as
the assumptions we've made for this project, we came up with the following
implementations for our chatbot, with one using a focusing on answering
questions accurately and the other focused on making sure generated dialogue is
as natural as possible. The two different implementations are built on the same
common-base for easy comparison and development.

\subsection{Chatbot Framework}

The overall chatbot framework is fairly straightforward to use. Starting up the
program starts a chatbot read-print-eval loop that initializes the model used
and corresponding data structures then starts reading user input. User input is
concatenated until a specified end of input indicator is inserted on a new line
(\verb|(over)|, \verb|(o)|, or \verb|.|), then the framework feeds the
concatenated input to the model, retrieves a response as a string, and prints
the respond using a formatter that prints out strings in the required output
format. If a end session indicator is specified (\verb|(over and out)|,
\verb|(oo)|, or \verb|bye|), the framework checks if there is any remaining
input that the model should handle. If so, it tries to print the generated
response before it exits. Otherwise, a simple ``bye'' is printed before the
exit. Details on the specifics of each model and their surrounding
implementation will be described in the following two sections.

\subsection{Q\&A Model}

\subsection{Conversation Model}

\section{Testing}

\section{Results}

\section{Further Improvements}

\section{Conclusion}
